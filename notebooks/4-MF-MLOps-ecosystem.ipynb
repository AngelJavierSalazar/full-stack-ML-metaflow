{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b78d30c4-4b6c-4ed2-a61a-6e434f6db9d3",
   "metadata": {},
   "source": [
    "# Metaflow and the MLOps ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aae4cc-32d8-4c93-8c4c-3096557e6656",
   "metadata": {},
   "source": [
    "_Human-centricity_ is a foundational principle of Metaflow. As a result, MF strives to be compatible with all the other ML tools that you already use (and ones you may want to use!). In this lesson, we'll show how to incorporate 2 _types of tools_, those for \n",
    "* experiment tracking and\n",
    "* data validation.\n",
    "\n",
    "We'll be using Weights & Biases for the former and Great Expectations for the latter, but keep in mind that Metaflow is agnostic with respect to the other tools you use. Let's jump in:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c332dddb-cea3-4cb0-ac41-ef8af6db24fc",
   "metadata": {},
   "source": [
    "## Experiment Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3755bb-e811-4e66-8b8e-25cf7f8d3b27",
   "metadata": {},
   "source": [
    "[TO-DO: provide brief intro to experiment tracking]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfde6ba-7bad-4122-b503-690e948fe498",
   "metadata": {},
   "source": [
    "Note that I've already logged into wandb using my terminal. \n",
    "\n",
    "[TO DO: include instructions on this, or a link, or instructions on putting credentials as env vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6a57436-3384-4d2d-bebc-6c5280c3e85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../flows/rf_flow_monitor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../flows/rf_flow_monitor.py\n",
    "from metaflow import FlowSpec, step, Parameter, JSONType, IncludeFile, card\n",
    "import json\n",
    "\n",
    "class ClassificationFlow(FlowSpec):\n",
    "    \"\"\"\n",
    "    train a random forest\n",
    "    \"\"\"\n",
    "    @card \n",
    "    @step\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Load the data\n",
    "        \"\"\"\n",
    "        #Import scikit-learn dataset library\n",
    "        from sklearn import datasets\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        #Load dataset\n",
    "        self.iris = datasets.load_iris()\n",
    "        self.X = self.iris['data']\n",
    "        self.y = self.iris['target']\n",
    "        self.labels = self.iris['target_names']\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2)\n",
    "        self.next(self.rf_model)\n",
    "        \n",
    "\n",
    "    @step\n",
    "    def rf_model(self):\n",
    "        \"\"\"\n",
    "        build random forest model\n",
    "        \"\"\"\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        \n",
    "        \n",
    "        self.clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "            min_samples_split=2, random_state=0)\n",
    "        self.next(self.train)\n",
    "\n",
    "        \n",
    "        \n",
    "    @step\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        import wandb\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        self.clf.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = self.clf.predict(self.X_test)\n",
    "        self.y_probs = self.clf.predict_proba(self.X_test)\n",
    "        self.next(self.monitor)\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "    @step\n",
    "    def monitor(self):\n",
    "        \"\"\"\n",
    "        plot some things using an experiment tracker\n",
    "        \n",
    "        \"\"\"\n",
    "        import wandb\n",
    "        wandb.init(project=\"mf-rf-wandb\", entity=\"hugobowne\", name=\"mf-tutorial-iris\")\n",
    "\n",
    "        wandb.sklearn.plot_class_proportions(self.y_train, self.y_test, self.labels)\n",
    "        wandb.sklearn.plot_learning_curve(self.clf, self.X_train, self.y_train)\n",
    "        wandb.sklearn.plot_roc(self.y_test, self.y_probs, self.labels)\n",
    "        wandb.sklearn.plot_precision_recall(self.y_test, self.y_probs, self.labels)\n",
    "        wandb.sklearn.plot_feature_importances(self.clf)\n",
    "\n",
    "        wandb.sklearn.plot_classifier(self.clf, \n",
    "                              self.X_train, self.X_test, \n",
    "                              self.y_train, self.y_test, \n",
    "                              self.y_pred, self.y_probs, \n",
    "                              self.labels, \n",
    "                              is_binary=True, \n",
    "                              model_name='RandomForest')\n",
    "\n",
    "        wandb.finish()\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        \"\"\"\n",
    "        End of flow, yo!\n",
    "        \"\"\"\n",
    "        print(\"ClassificationFlow is all done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ClassificationFlow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dd347c-d95f-4a6e-92be-e803c55b5e96",
   "metadata": {},
   "source": [
    "Execute the above from the command line with\n",
    "\n",
    "```bash\n",
    "! python ../flows/rf_flow_monitor.py run\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c94e4be-e6fd-4cfe-b45b-98bbe2ac4efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.5.0\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mClassificationFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:hba\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-03-26 11:10:43.293 \u001b[0m\u001b[1mWorkflow starting (run-id 7824):\u001b[0m\n",
      "\u001b[35m2022-03-26 11:10:49.260 \u001b[0m\u001b[32m[7824/start/138382 (pid 3358)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:11:34.641 \u001b[0m\u001b[32m[7824/start/138382 (pid 3358)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:11:38.541 \u001b[0m\u001b[32m[7824/rf_model/138383 (pid 3405)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:11:55.406 \u001b[0m\u001b[32m[7824/rf_model/138383 (pid 3405)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:11:59.280 \u001b[0m\u001b[32m[7824/train/138384 (pid 3414)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:21.447 \u001b[0m\u001b[32m[7824/train/138384 (pid 3414)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:25.421 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:34.211 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22mwandb: Currently logged in as: hugobowne (use `wandb login --relogin` to force relogin)\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:40.399 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22mwandb: Tracking run with wandb version 0.12.11\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:40.399 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22mwandb: Run data is saved locally in /Users/hba/Documents/Projects/full-stack-ML-metaflow-tutorial-main/notebooks/wandb/run-20220326_111234-1qaxs09y\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:40.401 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22mwandb: Run `wandb offline` to turn off syncing.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:40.401 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22mwandb: Syncing run mf-tutorial-iris\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:45.368 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22mwandb: ‚≠êÔ∏è View project at https://wandb.ai/hugobowne/mf-rf-wandb\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:45.368 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22mwandb: üöÄ View run at https://wandb.ai/hugobowne/mf-rf-wandb/runs/1qaxs09y\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:45.368 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb.plots.* functions are deprecated and will be removed in a future release. Please use wandb.plot.* instead.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:48.512 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m:\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:49.314 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Plotting RandomForest.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:49.314 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged feature importances.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:50.223 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged confusion matrix.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:51.032 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged summary metrics.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:52.065 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged class proportions.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:53.028 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m This function only supports binary classification at the moment and therefore expects labels to be binary. Skipping calibration curve.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:53.029 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged calibration curve.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:53.029 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged roc curve.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:53.830 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged precision-recall curve.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:56.062 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2022-03-26 11:12:56.063 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22mwandb: Waiting for W&B process to finish... (success).\u001b[0m\n",
      "wandb:\u001b[0m.030 MB of 0.030 MB uploaded (0.000 MB deduped)5 (pid 3435)] \u001b[0m\u001b[22mwandb: - 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\n",
      "\u001b[35m2022-03-26 11:13:17.513 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22mwandb: Synced mf-tutorial-iris: https://wandb.ai/hugobowne/mf-rf-wandb/runs/1qaxs09y\u001b[0m\n",
      "\u001b[35m2022-03-26 11:13:17.513 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22mwandb: Synced 6 W&B file(s), 11 media file(s), 7 artifact file(s) and 0 other file(s)\u001b[0m\n",
      "\u001b[35m2022-03-26 11:13:17.513 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[22mwandb: Find logs at: ./wandb/run-20220326_111234-1qaxs09y/logs\u001b[0m\n",
      "\u001b[35m2022-03-26 11:13:31.569 \u001b[0m\u001b[32m[7824/monitor/138385 (pid 3435)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:13:35.856 \u001b[0m\u001b[32m[7824/end/138386 (pid 3463)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:13:42.962 \u001b[0m\u001b[32m[7824/end/138386 (pid 3463)] \u001b[0m\u001b[22mClassificationFlow is all done.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:13:51.615 \u001b[0m\u001b[32m[7824/end/138386 (pid 3463)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:13:52.767 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python ../flows/rf_flow_monitor.py run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6ed88c-1cf1-491b-8c85-c1dfe142a294",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/hugobowne/mf-rf-wandb/workspace?jupyter=true\" style=\"border:none;width:100%;height:420px;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.IFrame at 0x7fef9098ab20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "%wandb hugobowne/mf-rf-wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883ddef8-2af8-4b51-9d1a-cbdff17cdce3",
   "metadata": {},
   "source": [
    "## Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37ff703-f242-462e-b5de-4f9c6051504d",
   "metadata": {},
   "source": [
    "**NOTE:** THE REST OF THIS NB IS PRETTY MUCH JUST CODE. WILL WRITE MORE WORDS SOON~ -- HBA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d22101-5fea-4871-aff6-ff0e93f09b1a",
   "metadata": {},
   "source": [
    "```\n",
    "@step\n",
    "def data_validation(self):\n",
    "    \"\"\"\n",
    "    Perform data validation with great_expectations\n",
    "    \"\"\"\n",
    "    from data_validation import validate_data\n",
    "\n",
    "    validate_data(current.run_id, current.flow_name, self.data_paths)\n",
    "\n",
    "    self.next(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b40f81-083a-49c0-ae96-e02cf7876f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../flows/iris_validate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../flows/iris_validate.py\n",
    "\n",
    "from metaflow import FlowSpec, step, Parameter, JSONType, IncludeFile, card\n",
    "import json\n",
    "\n",
    "class ClassificationFlow(FlowSpec):\n",
    "    \"\"\"\n",
    "    train a random forest\n",
    "    \"\"\"\n",
    "    @card \n",
    "    @step\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Load the data\n",
    "        \"\"\"\n",
    "        #Import scikit-learn dataset library\n",
    "        from sklearn import datasets\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        #Load dataset\n",
    "        self.iris = datasets.load_iris()\n",
    "        self.X = self.iris['data']\n",
    "        self.y = self.iris['target']\n",
    "        self.labels = self.iris['target_names']\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2)\n",
    "        self.next(self.data_validation)\n",
    "        \n",
    "\n",
    "\n",
    "    @step\n",
    "    def data_validation(self):\n",
    "        \"\"\"\n",
    "        Perform data validation with great_expectations\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        from ruamel import yaml\n",
    "        import great_expectations as ge\n",
    "        from great_expectations.core.batch import RuntimeBatchRequest\n",
    "\n",
    "        context = ge.get_context()\n",
    "\n",
    "        \n",
    "        from sklearn import datasets\n",
    "        iris = datasets.load_iris()\n",
    "        df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
    "        df[\"target\"] = iris['target']\n",
    "        # df[\"sepal length (cm)\"][0] = -1\n",
    "\n",
    "\n",
    "        checkpoint_config = {\n",
    "            \"name\": \"flowers-test-flow-checkpoint\",\n",
    "            \"config_version\": 1,\n",
    "            \"class_name\": \"SimpleCheckpoint\",\n",
    "            \"run_name_template\": \"%Y%m%d-%H%M%S-flower-power\",\n",
    "            \"validations\": [\n",
    "                {\n",
    "                    \"batch_request\": {\n",
    "                        \"datasource_name\": \"flowers\",\n",
    "                        \"data_connector_name\": \"default_runtime_data_connector_name\",\n",
    "                        \"data_asset_name\": \"iris\",\n",
    "                    },\n",
    "                    \"expectation_suite_name\": \"flowers-testing-suite\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "        context.add_checkpoint(**checkpoint_config)\n",
    "\n",
    "\n",
    "        results = context.run_checkpoint(\n",
    "            checkpoint_name=\"flowers-test-flow-checkpoint\",\n",
    "            batch_request={\n",
    "                \"runtime_parameters\": {\"batch_data\": df},\n",
    "                \"batch_identifiers\": {\n",
    "                    \"default_identifier_name\": \"<YOUR MEANINGFUL IDENTIFIER>\"\n",
    "                },\n",
    "            },\n",
    "        )\n",
    "        context.build_data_docs()\n",
    "        context.open_data_docs()\n",
    "\n",
    "        self.next(self.end)\n",
    "        \n",
    "        \n",
    "#     @step\n",
    "#     def rf_model(self):\n",
    "#         \"\"\"\n",
    "#         build random forest model\n",
    "#         \"\"\"\n",
    "#         from sklearn.ensemble import RandomForestClassifier\n",
    "        \n",
    "        \n",
    "#         self.clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "#             min_samples_split=2, random_state=0)\n",
    "#         self.next(self.train)\n",
    "\n",
    "        \n",
    "        \n",
    "#     @step\n",
    "#     def train(self):\n",
    "#         \"\"\"\n",
    "#         Train the model\n",
    "#         \"\"\"\n",
    "#         import wandb\n",
    "#         from sklearn.model_selection import cross_val_score\n",
    "#         self.clf.fit(self.X_train, self.y_train)\n",
    "#         self.y_pred = self.clf.predict(self.X_test)\n",
    "#         self.y_probs = self.clf.predict_proba(self.X_test)\n",
    "#         self.next(self.monitor)\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "#     @step\n",
    "#     def monitor(self):\n",
    "#         \"\"\"\n",
    "#         plot some things using an experiment tracker\n",
    "        \n",
    "#         \"\"\"\n",
    "#         import wandb\n",
    "#         wandb.init(project=\"mf-rf-wandb\", entity=\"hugobowne\", name=\"mf-tutorial-iris\")\n",
    "\n",
    "#         wandb.sklearn.plot_class_proportions(self.y_train, self.y_test, self.labels)\n",
    "#         wandb.sklearn.plot_learning_curve(self.clf, self.X_train, self.y_train)\n",
    "#         wandb.sklearn.plot_roc(self.y_test, self.y_probs, self.labels)\n",
    "#         wandb.sklearn.plot_precision_recall(self.y_test, self.y_probs, self.labels)\n",
    "#         wandb.sklearn.plot_feature_importances(self.clf)\n",
    "\n",
    "#         wandb.sklearn.plot_classifier(self.clf, \n",
    "#                               self.X_train, self.X_test, \n",
    "#                               self.y_train, self.y_test, \n",
    "#                               self.y_pred, self.y_probs, \n",
    "#                               self.labels, \n",
    "#                               is_binary=True, \n",
    "#                               model_name='RandomForest')\n",
    "\n",
    "#         wandb.finish()\n",
    "#         self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        \"\"\"\n",
    "        End of flow, yo!\n",
    "        \"\"\"\n",
    "        print(\"ClassificationFlow is all done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ClassificationFlow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca01ecb-df2b-4009-902d-a406396a9cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.5.0\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mClassificationFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:hba\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-03-26 11:14:54.195 \u001b[0m\u001b[1mWorkflow starting (run-id 7825):\u001b[0m\n",
      "\u001b[35m2022-03-26 11:15:00.017 \u001b[0m\u001b[32m[7825/start/138388 (pid 3495)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:15:44.655 \u001b[0m\u001b[32m[7825/start/138388 (pid 3495)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:15:48.437 \u001b[0m\u001b[32m[7825/data_validation/138389 (pid 3522)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:15:56.721 \u001b[0m\u001b[32m[7825/data_validation/138389 (pid 3522)] \u001b[0m\u001b[22m/Users/hba/opt/anaconda3/envs/full-stack-metaflow/lib/python3.8/site-packages/sklearn/feature_extraction/image.py:172: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:15:56.744 \u001b[0m\u001b[32m[7825/data_validation/138389 (pid 3522)] \u001b[0m\u001b[22mDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\u001b[0m\n",
      "\u001b[35m2022-03-26 11:15:56.744 \u001b[0m\u001b[32m[7825/data_validation/138389 (pid 3522)] \u001b[0m\u001b[22mdtype=np.int):\u001b[0m\n",
      "\u001b[35m2022-03-26 11:15:56.744 \u001b[0m\u001b[32m[7825/data_validation/138389 (pid 3522)] \u001b[0m\u001b[22m/Users/hba/opt/anaconda3/envs/full-stack-metaflow/lib/python3.8/site-packages/sklearn/datasets/_base.py:263: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:15:56.891 \u001b[0m\u001b[32m[7825/data_validation/138389 (pid 3522)] \u001b[0m\u001b[22mDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\u001b[0m\n",
      "\u001b[35m2022-03-26 11:15:56.892 \u001b[0m\u001b[32m[7825/data_validation/138389 (pid 3522)] \u001b[0m\u001b[22mtarget = np.empty((n_samples,), dtype=np.int)\u001b[0m\n",
      "\u001b[35m2022-03-26 11:15:56.892 \u001b[0m\u001b[32m[7825/data_validation/138389 (pid 3522)] \u001b[0m\u001b[22m/Users/hba/opt/anaconda3/envs/full-stack-metaflow/lib/python3.8/site-packages/sklearn/datasets/_base.py:267: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:15:56.892 \u001b[0m\u001b[32m[7825/data_validation/138389 (pid 3522)] \u001b[0m\u001b[22mDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\u001b[0m\n",
      "\u001b[35m2022-03-26 11:15:56.892 \u001b[0m\u001b[32m[7825/data_validation/138389 (pid 3522)] \u001b[0m\u001b[22mtarget[i] = np.asarray(ir[-1], dtype=np.int)\u001b[0m\n",
      "Calculating Metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:00<00:00, 326.70it/s]\u001b[0m522)] \u001b[0m\u001b[22mCalculating Metrics:   0%|          | 0/21 [00:00<?, ?it/s]\n",
      "\u001b[35m2022-03-26 11:16:07.914 \u001b[0m\u001b[32m[7825/data_validation/138389 (pid 3522)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:16:12.127 \u001b[0m\u001b[32m[7825/end/138390 (pid 3559)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:16:19.281 \u001b[0m\u001b[32m[7825/end/138390 (pid 3559)] \u001b[0m\u001b[22mClassificationFlow is all done.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:16:27.911 \u001b[0m\u001b[32m[7825/end/138390 (pid 3559)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:16:29.249 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python ../flows/iris_validate.py run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358ef640-ef2d-4b43-ae59-7e4d5faa44e2",
   "metadata": {},
   "source": [
    "## Combination station!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0fed65c-a518-46d5-98c1-b91de4b0feb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../flows/rf_flow_monitor_validate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../flows/rf_flow_monitor_validate.py\n",
    "\n",
    "from metaflow import FlowSpec, step, Parameter, JSONType, IncludeFile, card\n",
    "import json\n",
    "\n",
    "class ClassificationFlow(FlowSpec):\n",
    "    \"\"\"\n",
    "    train a random forest\n",
    "    \"\"\"\n",
    "    @card \n",
    "    @step\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Load the data\n",
    "        \"\"\"\n",
    "        #Import scikit-learn dataset library\n",
    "        from sklearn import datasets\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        #Load dataset\n",
    "        self.iris = datasets.load_iris()\n",
    "        self.X = self.iris['data']\n",
    "        self.y = self.iris['target']\n",
    "        self.labels = self.iris['target_names']\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2)\n",
    "        self.next(self.data_validation)\n",
    "        \n",
    "\n",
    "    @step\n",
    "    def data_validation(self):\n",
    "        \"\"\"\n",
    "        Perform data validation with great_expectations\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        from ruamel import yaml\n",
    "        import great_expectations as ge\n",
    "        from great_expectations.core.batch import RuntimeBatchRequest\n",
    "\n",
    "        context = ge.get_context()\n",
    "\n",
    "        \n",
    "        from sklearn import datasets\n",
    "        iris = datasets.load_iris()\n",
    "        df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
    "        df[\"target\"] = iris['target']\n",
    "        # df[\"sepal length (cm)\"][0] = -1\n",
    "\n",
    "\n",
    "        checkpoint_config = {\n",
    "            \"name\": \"flowers-test-flow-checkpoint\",\n",
    "            \"config_version\": 1,\n",
    "            \"class_name\": \"SimpleCheckpoint\",\n",
    "            \"run_name_template\": \"%Y%m%d-%H%M%S-flower-power\",\n",
    "            \"validations\": [\n",
    "                {\n",
    "                    \"batch_request\": {\n",
    "                        \"datasource_name\": \"flowers\",\n",
    "                        \"data_connector_name\": \"default_runtime_data_connector_name\",\n",
    "                        \"data_asset_name\": \"iris\",\n",
    "                    },\n",
    "                    \"expectation_suite_name\": \"flowers-testing-suite\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "        context.add_checkpoint(**checkpoint_config)\n",
    "\n",
    "\n",
    "        results = context.run_checkpoint(\n",
    "            checkpoint_name=\"flowers-test-flow-checkpoint\",\n",
    "            batch_request={\n",
    "                \"runtime_parameters\": {\"batch_data\": df},\n",
    "                \"batch_identifiers\": {\n",
    "                    \"default_identifier_name\": \"<YOUR MEANINGFUL IDENTIFIER>\"\n",
    "                },\n",
    "            },\n",
    "        )\n",
    "        context.build_data_docs()\n",
    "        context.open_data_docs()\n",
    "\n",
    "        self.next(self.rf_model)\n",
    "        \n",
    "        \n",
    "    @step\n",
    "    def rf_model(self):\n",
    "        \"\"\"\n",
    "        build random forest model\n",
    "        \"\"\"\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        \n",
    "        \n",
    "        self.clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "            min_samples_split=2, random_state=0)\n",
    "        self.next(self.train)\n",
    "\n",
    "        \n",
    "        \n",
    "    @step\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        import wandb\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        self.clf.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = self.clf.predict(self.X_test)\n",
    "        self.y_probs = self.clf.predict_proba(self.X_test)\n",
    "        self.next(self.monitor)\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "    @step\n",
    "    def monitor(self):\n",
    "        \"\"\"\n",
    "        plot some things using an experiment tracker\n",
    "        \n",
    "        \"\"\"\n",
    "        import wandb\n",
    "        wandb.init(project=\"mf-rf-wandb\", entity=\"hugobowne\", name=\"mf-tutorial-iris\")\n",
    "\n",
    "        wandb.sklearn.plot_class_proportions(self.y_train, self.y_test, self.labels)\n",
    "        wandb.sklearn.plot_learning_curve(self.clf, self.X_train, self.y_train)\n",
    "        wandb.sklearn.plot_roc(self.y_test, self.y_probs, self.labels)\n",
    "        wandb.sklearn.plot_precision_recall(self.y_test, self.y_probs, self.labels)\n",
    "        wandb.sklearn.plot_feature_importances(self.clf)\n",
    "\n",
    "        wandb.sklearn.plot_classifier(self.clf, \n",
    "                              self.X_train, self.X_test, \n",
    "                              self.y_train, self.y_test, \n",
    "                              self.y_pred, self.y_probs, \n",
    "                              self.labels, \n",
    "                              is_binary=True, \n",
    "                              model_name='RandomForest')\n",
    "\n",
    "        wandb.finish()\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        \"\"\"\n",
    "        End of flow, yo!\n",
    "        \"\"\"\n",
    "        print(\"ClassificationFlow is all done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ClassificationFlow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c311f62a-b72c-4576-8088-3b5951e263f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.5.0\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mClassificationFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:hba\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-03-26 11:16:45.707 \u001b[0m\u001b[1mWorkflow starting (run-id 7826):\u001b[0m\n",
      "\u001b[35m2022-03-26 11:16:51.487 \u001b[0m\u001b[32m[7826/start/138392 (pid 3580)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:17:36.845 \u001b[0m\u001b[32m[7826/start/138392 (pid 3580)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:17:40.769 \u001b[0m\u001b[32m[7826/data_validation/138393 (pid 3630)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:17:49.374 \u001b[0m\u001b[32m[7826/data_validation/138393 (pid 3630)] \u001b[0m\u001b[22m/Users/hba/opt/anaconda3/envs/full-stack-metaflow/lib/python3.8/site-packages/sklearn/feature_extraction/image.py:172: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:17:49.399 \u001b[0m\u001b[32m[7826/data_validation/138393 (pid 3630)] \u001b[0m\u001b[22mDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\u001b[0m\n",
      "\u001b[35m2022-03-26 11:17:49.399 \u001b[0m\u001b[32m[7826/data_validation/138393 (pid 3630)] \u001b[0m\u001b[22mdtype=np.int):\u001b[0m\n",
      "\u001b[35m2022-03-26 11:17:49.399 \u001b[0m\u001b[32m[7826/data_validation/138393 (pid 3630)] \u001b[0m\u001b[22m/Users/hba/opt/anaconda3/envs/full-stack-metaflow/lib/python3.8/site-packages/sklearn/datasets/_base.py:263: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:17:49.554 \u001b[0m\u001b[32m[7826/data_validation/138393 (pid 3630)] \u001b[0m\u001b[22mDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\u001b[0m\n",
      "\u001b[35m2022-03-26 11:17:49.554 \u001b[0m\u001b[32m[7826/data_validation/138393 (pid 3630)] \u001b[0m\u001b[22mtarget = np.empty((n_samples,), dtype=np.int)\u001b[0m\n",
      "\u001b[35m2022-03-26 11:17:49.554 \u001b[0m\u001b[32m[7826/data_validation/138393 (pid 3630)] \u001b[0m\u001b[22m/Users/hba/opt/anaconda3/envs/full-stack-metaflow/lib/python3.8/site-packages/sklearn/datasets/_base.py:267: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:17:49.554 \u001b[0m\u001b[32m[7826/data_validation/138393 (pid 3630)] \u001b[0m\u001b[22mDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\u001b[0m\n",
      "\u001b[35m2022-03-26 11:17:49.554 \u001b[0m\u001b[32m[7826/data_validation/138393 (pid 3630)] \u001b[0m\u001b[22mtarget[i] = np.asarray(ir[-1], dtype=np.int)\u001b[0m\n",
      "Calculating Metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:00<00:00, 317.36it/s]\u001b[0m630)] \u001b[0m\u001b[22mCalculating Metrics:   0%|          | 0/21 [00:00<?, ?it/s]\n",
      "\u001b[35m2022-03-26 11:18:00.890 \u001b[0m\u001b[32m[7826/data_validation/138393 (pid 3630)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:18:04.876 \u001b[0m\u001b[32m[7826/rf_model/138394 (pid 3667)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:18:21.226 \u001b[0m\u001b[32m[7826/rf_model/138394 (pid 3667)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:18:25.096 \u001b[0m\u001b[32m[7826/train/138395 (pid 3680)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:18:47.464 \u001b[0m\u001b[32m[7826/train/138395 (pid 3680)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:18:51.378 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:18:59.696 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22mwandb: Currently logged in as: hugobowne (use `wandb login --relogin` to force relogin)\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:05.542 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22mwandb: Tracking run with wandb version 0.12.11\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:05.542 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22mwandb: Run data is saved locally in /Users/hba/Documents/Projects/full-stack-ML-metaflow-tutorial-main/notebooks/wandb/run-20220326_111859-1lpjjaac\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:05.543 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22mwandb: Run `wandb offline` to turn off syncing.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:05.543 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22mwandb: Syncing run mf-tutorial-iris\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:10.560 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22mwandb: ‚≠êÔ∏è View project at https://wandb.ai/hugobowne/mf-rf-wandb\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:10.561 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22mwandb: üöÄ View run at https://wandb.ai/hugobowne/mf-rf-wandb/runs/1lpjjaac\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:10.561 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb.plots.* functions are deprecated and will be removed in a future release. Please use wandb.plot.* instead.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:13.566 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m:\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:14.527 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Plotting RandomForest.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:14.528 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged feature importances.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:15.449 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged confusion matrix.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:16.281 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged summary metrics.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:17.072 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged class proportions.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:17.077 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m This function only supports binary classification at the moment and therefore expects labels to be binary. Skipping calibration curve.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:17.945 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged calibration curve.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:17.945 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged roc curve.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:18.787 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged precision-recall curve.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:21.156 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:21.157 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22mwandb: Waiting for W&B process to finish... (success).\u001b[0m\n",
      "wandb:\u001b[0m.030 MB of 0.030 MB uploaded (0.000 MB deduped)6 (pid 3698)] \u001b[0m\u001b[22mwandb: - 0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\n",
      "\u001b[35m2022-03-26 11:19:37.420 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22mwandb: Synced mf-tutorial-iris: https://wandb.ai/hugobowne/mf-rf-wandb/runs/1lpjjaac\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:37.420 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22mwandb: Synced 6 W&B file(s), 11 media file(s), 7 artifact file(s) and 0 other file(s)\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:37.420 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[22mwandb: Find logs at: ./wandb/run-20220326_111859-1lpjjaac/logs\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:51.776 \u001b[0m\u001b[32m[7826/monitor/138396 (pid 3698)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:19:55.991 \u001b[0m\u001b[32m[7826/end/138397 (pid 3728)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:20:03.107 \u001b[0m\u001b[32m[7826/end/138397 (pid 3728)] \u001b[0m\u001b[22mClassificationFlow is all done.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:20:11.735 \u001b[0m\u001b[32m[7826/end/138397 (pid 3728)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:20:12.876 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python ../flows/rf_flow_monitor_validate.py run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2abfb90d-27ba-4b2e-ab5b-bdb7f0cb02c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/hugobowne/mf-rf-wandb/workspace?jupyter=true\" style=\"border:none;width:100%;height:420px;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.IFrame at 0x7fef909a49d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import wandb\n",
    "%wandb hugobowne/mf-rf-wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2178dc7-278d-420d-b666-5bd20628eb3d",
   "metadata": {},
   "source": [
    "## Data Not Validated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4f4c88-a94c-45f2-ab7e-f13d16e5fe3c",
   "metadata": {},
   "source": [
    "Let's do the above again but edit the data slightly so that it doesn't pass all our tests, to make sure that the tests are working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a14cc46-5c20-4183-b47c-34bbdba5d902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../flows/rf_flow_monitor_validate_bad_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../flows/rf_flow_monitor_validate_bad_data.py\n",
    "\n",
    "from metaflow import FlowSpec, step, Parameter, JSONType, IncludeFile, card\n",
    "import json\n",
    "\n",
    "class ClassificationFlow(FlowSpec):\n",
    "    \"\"\"\n",
    "    train a random forest\n",
    "    \"\"\"\n",
    "    @card \n",
    "    @step\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Load the data\n",
    "        \"\"\"\n",
    "        #Import scikit-learn dataset library\n",
    "        from sklearn import datasets\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        #Load dataset\n",
    "        self.iris = datasets.load_iris()\n",
    "        self.X = self.iris['data']\n",
    "        self.y = self.iris['target']\n",
    "        self.labels = self.iris['target_names']\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2)\n",
    "        self.next(self.data_validation)\n",
    "        \n",
    "\n",
    "    @step\n",
    "    def data_validation(self):\n",
    "        \"\"\"\n",
    "        Perform data validation with great_expectations\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        from ruamel import yaml\n",
    "        import great_expectations as ge\n",
    "        from great_expectations.core.batch import RuntimeBatchRequest\n",
    "\n",
    "        context = ge.get_context()\n",
    "\n",
    "        \n",
    "        from sklearn import datasets\n",
    "        iris = datasets.load_iris()\n",
    "        df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
    "        df[\"target\"] = iris['target']\n",
    "        df[\"petal length (cm)\"][0] = -1\n",
    "\n",
    "\n",
    "        checkpoint_config = {\n",
    "            \"name\": \"flowers-test-flow-checkpoint\",\n",
    "            \"config_version\": 1,\n",
    "            \"class_name\": \"SimpleCheckpoint\",\n",
    "            \"run_name_template\": \"%Y%m%d-%H%M%S-flower-power\",\n",
    "            \"validations\": [\n",
    "                {\n",
    "                    \"batch_request\": {\n",
    "                        \"datasource_name\": \"flowers\",\n",
    "                        \"data_connector_name\": \"default_runtime_data_connector_name\",\n",
    "                        \"data_asset_name\": \"iris\",\n",
    "                    },\n",
    "                    \"expectation_suite_name\": \"flowers-testing-suite\",\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "        context.add_checkpoint(**checkpoint_config)\n",
    "\n",
    "\n",
    "        results = context.run_checkpoint(\n",
    "            checkpoint_name=\"flowers-test-flow-checkpoint\",\n",
    "            batch_request={\n",
    "                \"runtime_parameters\": {\"batch_data\": df},\n",
    "                \"batch_identifiers\": {\n",
    "                    \"default_identifier_name\": \"<YOUR MEANINGFUL IDENTIFIER>\"\n",
    "                },\n",
    "            },\n",
    "        )\n",
    "        context.build_data_docs()\n",
    "        context.open_data_docs()\n",
    "\n",
    "        self.next(self.rf_model)\n",
    "        \n",
    "        \n",
    "    @step\n",
    "    def rf_model(self):\n",
    "        \"\"\"\n",
    "        build random forest model\n",
    "        \"\"\"\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        \n",
    "        \n",
    "        self.clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "            min_samples_split=2, random_state=0)\n",
    "        self.next(self.train)\n",
    "\n",
    "        \n",
    "        \n",
    "    @step\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        import wandb\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        self.clf.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = self.clf.predict(self.X_test)\n",
    "        self.y_probs = self.clf.predict_proba(self.X_test)\n",
    "        self.next(self.monitor)\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "    @step\n",
    "    def monitor(self):\n",
    "        \"\"\"\n",
    "        plot some things using an experiment tracker\n",
    "        \n",
    "        \"\"\"\n",
    "        import wandb\n",
    "        wandb.init(project=\"mf-rf-wandb\", entity=\"hugobowne\", name=\"mf-tutorial-iris\")\n",
    "\n",
    "        wandb.sklearn.plot_class_proportions(self.y_train, self.y_test, self.labels)\n",
    "        wandb.sklearn.plot_learning_curve(self.clf, self.X_train, self.y_train)\n",
    "        wandb.sklearn.plot_roc(self.y_test, self.y_probs, self.labels)\n",
    "        wandb.sklearn.plot_precision_recall(self.y_test, self.y_probs, self.labels)\n",
    "        wandb.sklearn.plot_feature_importances(self.clf)\n",
    "\n",
    "        wandb.sklearn.plot_classifier(self.clf, \n",
    "                              self.X_train, self.X_test, \n",
    "                              self.y_train, self.y_test, \n",
    "                              self.y_pred, self.y_probs, \n",
    "                              self.labels, \n",
    "                              is_binary=True, \n",
    "                              model_name='RandomForest')\n",
    "\n",
    "        wandb.finish()\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        \"\"\"\n",
    "        End of flow, yo!\n",
    "        \"\"\"\n",
    "        print(\"ClassificationFlow is all done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ClassificationFlow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1a990b8-609a-4a7b-a9c4-2b9e51b48c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.5.0\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mClassificationFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:hba\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-03-26 11:22:51.783 \u001b[0m\u001b[1mWorkflow starting (run-id 7827):\u001b[0m\n",
      "\u001b[35m2022-03-26 11:22:57.656 \u001b[0m\u001b[32m[7827/start/138399 (pid 3768)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:23:41.731 \u001b[0m\u001b[32m[7827/start/138399 (pid 3768)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:23:45.541 \u001b[0m\u001b[32m[7827/data_validation/138400 (pid 3808)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:23:54.061 \u001b[0m\u001b[32m[7827/data_validation/138400 (pid 3808)] \u001b[0m\u001b[22m/Users/hba/opt/anaconda3/envs/full-stack-metaflow/lib/python3.8/site-packages/sklearn/feature_extraction/image.py:172: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:23:54.086 \u001b[0m\u001b[32m[7827/data_validation/138400 (pid 3808)] \u001b[0m\u001b[22mDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\u001b[0m\n",
      "\u001b[35m2022-03-26 11:23:54.086 \u001b[0m\u001b[32m[7827/data_validation/138400 (pid 3808)] \u001b[0m\u001b[22mdtype=np.int):\u001b[0m\n",
      "\u001b[35m2022-03-26 11:23:54.086 \u001b[0m\u001b[32m[7827/data_validation/138400 (pid 3808)] \u001b[0m\u001b[22m/Users/hba/opt/anaconda3/envs/full-stack-metaflow/lib/python3.8/site-packages/sklearn/datasets/_base.py:263: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:23:54.239 \u001b[0m\u001b[32m[7827/data_validation/138400 (pid 3808)] \u001b[0m\u001b[22mDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\u001b[0m\n",
      "\u001b[35m2022-03-26 11:23:54.239 \u001b[0m\u001b[32m[7827/data_validation/138400 (pid 3808)] \u001b[0m\u001b[22mtarget = np.empty((n_samples,), dtype=np.int)\u001b[0m\n",
      "\u001b[35m2022-03-26 11:23:54.239 \u001b[0m\u001b[32m[7827/data_validation/138400 (pid 3808)] \u001b[0m\u001b[22m/Users/hba/opt/anaconda3/envs/full-stack-metaflow/lib/python3.8/site-packages/sklearn/datasets/_base.py:267: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:23:54.239 \u001b[0m\u001b[32m[7827/data_validation/138400 (pid 3808)] \u001b[0m\u001b[22mDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\u001b[0m\n",
      "\u001b[35m2022-03-26 11:23:54.239 \u001b[0m\u001b[32m[7827/data_validation/138400 (pid 3808)] \u001b[0m\u001b[22mtarget[i] = np.asarray(ir[-1], dtype=np.int)\u001b[0m\n",
      "Calculating Metrics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [00:00<00:00, 317.56it/s]\u001b[0m808)] \u001b[0m\u001b[22mCalculating Metrics:   0%|          | 0/21 [00:00<?, ?it/s]\n",
      "\u001b[35m2022-03-26 11:24:04.970 \u001b[0m\u001b[32m[7827/data_validation/138400 (pid 3808)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:24:09.025 \u001b[0m\u001b[32m[7827/rf_model/138401 (pid 3854)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:24:25.330 \u001b[0m\u001b[32m[7827/rf_model/138401 (pid 3854)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:24:29.135 \u001b[0m\u001b[32m[7827/train/138402 (pid 3861)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:24:50.660 \u001b[0m\u001b[32m[7827/train/138402 (pid 3861)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:24:54.569 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:02.713 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22mwandb: Currently logged in as: hugobowne (use `wandb login --relogin` to force relogin)\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:08.282 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22mwandb: Tracking run with wandb version 0.12.11\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:08.282 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22mwandb: Run data is saved locally in /Users/hba/Documents/Projects/full-stack-ML-metaflow-tutorial-main/notebooks/wandb/run-20220326_112502-rmp4rpfg\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:08.283 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22mwandb: Run `wandb offline` to turn off syncing.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:08.284 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22mwandb: Syncing run mf-tutorial-iris\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:13.068 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22mwandb: ‚≠êÔ∏è View project at https://wandb.ai/hugobowne/mf-rf-wandb\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:13.069 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22mwandb: üöÄ View run at https://wandb.ai/hugobowne/mf-rf-wandb/runs/rmp4rpfg\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:13.069 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb.plots.* functions are deprecated and will be removed in a future release. Please use wandb.plot.* instead.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:15.886 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m:\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:16.868 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Plotting RandomForest.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:16.869 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged feature importances.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:17.618 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged confusion matrix.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:18.490 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged summary metrics.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:19.600 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged class proportions.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:19.612 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m This function only supports binary classification at the moment and therefore expects labels to be binary. Skipping calibration curve.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:20.499 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged calibration curve.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:20.501 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged roc curve.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:21.404 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22m\u001b[34m\u001b[1mwandb\u001b[0m: Logged precision-recall curve.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:23.921 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:23.922 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22mwandb: Waiting for W&B process to finish... (success).\u001b[0m\n",
      "wandb:\u001b[0m.030 MB of 0.030 MB uploaded (0.000 MB deduped)3 (pid 3880)] \u001b[0m\u001b[22mwandb: - 0.011 MB of 0.013 MB uploaded (0.000 MB deduped)\n",
      "\u001b[35m2022-03-26 11:25:41.322 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22mwandb: Synced mf-tutorial-iris: https://wandb.ai/hugobowne/mf-rf-wandb/runs/rmp4rpfg\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:41.322 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22mwandb: Synced 6 W&B file(s), 11 media file(s), 7 artifact file(s) and 0 other file(s)\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:41.322 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[22mwandb: Find logs at: ./wandb/run-20220326_112502-rmp4rpfg/logs\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:55.091 \u001b[0m\u001b[32m[7827/monitor/138403 (pid 3880)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:25:59.365 \u001b[0m\u001b[32m[7827/end/138404 (pid 3907)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:26:06.529 \u001b[0m\u001b[32m[7827/end/138404 (pid 3907)] \u001b[0m\u001b[22mClassificationFlow is all done.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:26:15.287 \u001b[0m\u001b[32m[7827/end/138404 (pid 3907)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:26:16.415 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python ../flows/rf_flow_monitor_validate_bad_data.py run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73070de-927d-499c-830e-2f876bed7d7c",
   "metadata": {},
   "source": [
    "## Deploying your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "522dbcdd-b77d-40b9-91ff-41703352bbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../flows/RF-deploy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../flows/RF-deploy.py\n",
    "\n",
    "\n",
    "from metaflow import FlowSpec, step, Parameter, JSONType, IncludeFile, card, S3\n",
    "import json\n",
    "\n",
    "class ClassificationFlow(FlowSpec):\n",
    "    \"\"\"\n",
    "    train a random forest\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    @card \n",
    "    @step\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Load the data\n",
    "        \"\"\"\n",
    "        #Import scikit-learn dataset library\n",
    "        from sklearn import datasets\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        #Load dataset\n",
    "        self.iris = datasets.load_iris()\n",
    "        self.X = self.iris['data']\n",
    "        self.y = self.iris['target']\n",
    "        self.labels = self.iris['target_names']\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size=0.2)\n",
    "        self.next(self.rf_model)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    @step\n",
    "    def rf_model(self):\n",
    "        \"\"\"\n",
    "        build random forest model\n",
    "        \"\"\"\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        \n",
    "        \n",
    "        self.clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "            min_samples_split=2, random_state=0)\n",
    "        self.next(self.train)\n",
    "\n",
    "        \n",
    "        \n",
    "    @step\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        #import wandb\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        self.clf.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = self.clf.predict(self.X_test)\n",
    "        self.y_probs = self.clf.predict_proba(self.X_test)\n",
    "        self.next(self.deploy)\n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    @step\n",
    "    def deploy(self):\n",
    "        \"\"\"\n",
    "        Use SageMaker to deploy the model as a stand-alone, PaaS endpoint, with our choice of the underlying\n",
    "        Docker image and hardware capabilities.\n",
    "\n",
    "        Available images for inferences can be chosen from AWS official list:\n",
    "        https://github.com/aws/deep-learning-containers/blob/master/available_images.md\n",
    "\n",
    "        Once the endpoint is deployed, you can add a further step with for example behavioral testing, to\n",
    "        ensure model robustness (e.g. see https://arxiv.org/pdf/2005.04118.pdf). Here, we just \"prove\" that\n",
    "        the endpoint is up and running!\n",
    "\n",
    "        also see here: https://github.com/jacopotagliabue/FREE_7773/blob/main/mlsys/training/small_flow_sagemaker.py\n",
    "\n",
    "        \"\"\"\n",
    "        import os\n",
    "        import time\n",
    "        import joblib\n",
    "        import shutil\n",
    "        import tarfile\n",
    "        from sagemaker.sklearn import SKLearnModel\n",
    "\n",
    "\n",
    "        model_name = \"model\"\n",
    "        local_tar_name = \"model.tar.gz\"\n",
    "\n",
    "        os.makedirs(model_name, exist_ok=True)\n",
    "        # save model to local folder\n",
    "        joblib.dump(self.clf, \"{}/{}.joblib\".format(model_name, model_name))\n",
    "        # save model as tar.gz\n",
    "        with tarfile.open(local_tar_name, mode=\"w:gz\") as _tar:\n",
    "            _tar.add(model_name, recursive=True)\n",
    "        # save model onto S3\n",
    "        with S3(run=self) as s3:\n",
    "            with open(local_tar_name, \"rb\") as in_file:\n",
    "                data = in_file.read()\n",
    "                self.model_s3_path = s3.put(local_tar_name, data)\n",
    "                print('Model saved at {}'.format(self.model_s3_path))\n",
    "        # remove local model folder and tar\n",
    "        shutil.rmtree(model_name)\n",
    "        os.remove(local_tar_name)\n",
    "        # initialize SageMaker SKLearn Model\n",
    "        sklearn_model = SKLearnModel(model_data=self.model_s3_path,\n",
    "                                     role='oleg2-sagemaker-mztdpcvj',\n",
    "                                     entry_point='../flows/sm_entry_point.py',\n",
    "                                     framework_version='0.23-1',\n",
    "                                     code_location='s3://oleg2-s3-mztdpcvj/sagemaker/')\n",
    "        endpoint_name = 'HBA-RF-endpoint-{}'.format(int(round(time.time() * 1000)))\n",
    "        print(\"\\n\\n================\\nEndpoint name is: {}\\n\\n\".format(endpoint_name))\n",
    "        # deploy model\n",
    "        predictor = sklearn_model.deploy(instance_type='ml.c5.2xlarge',\n",
    "                                         initial_instance_count=1,\n",
    "                                         endpoint_name=endpoint_name)\n",
    "        # prepare a test input and check response\n",
    "        test_input = self.X\n",
    "        result = predictor.predict(test_input)\n",
    "        print(result)\n",
    "        \n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        \"\"\"\n",
    "        End of flow, yo!\n",
    "        \"\"\"\n",
    "        print(\"ClassificationFlow is all done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ClassificationFlow()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21d50b8b-bbf7-41d7-8c6b-63c3ed9c8386",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.5.0\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mClassificationFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:hba\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-03-26 11:29:29.956 \u001b[0m\u001b[1mWorkflow starting (run-id 7829):\u001b[0m\n",
      "\u001b[35m2022-03-26 11:29:35.861 \u001b[0m\u001b[32m[7829/start/138411 (pid 4032)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:30:20.303 \u001b[0m\u001b[32m[7829/start/138411 (pid 4032)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:30:24.100 \u001b[0m\u001b[32m[7829/rf_model/138412 (pid 4063)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:30:40.441 \u001b[0m\u001b[32m[7829/rf_model/138412 (pid 4063)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:30:44.236 \u001b[0m\u001b[32m[7829/train/138413 (pid 4092)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:31:05.604 \u001b[0m\u001b[32m[7829/train/138413 (pid 4092)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:31:09.486 \u001b[0m\u001b[32m[7829/deploy/138414 (pid 4108)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:31:19.129 \u001b[0m\u001b[32m[7829/deploy/138414 (pid 4108)] \u001b[0m\u001b[22mModel saved at s3://oleg2-s3-mztdpcvj/data/ClassificationFlow/7829/model.tar.gz\u001b[0m\n",
      "\u001b[35m2022-03-26 11:31:19.132 \u001b[0m\u001b[32m[7829/deploy/138414 (pid 4108)] \u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2022-03-26 11:31:23.716 \u001b[0m\u001b[32m[7829/deploy/138414 (pid 4108)] \u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2022-03-26 11:31:23.717 \u001b[0m\u001b[32m[7829/deploy/138414 (pid 4108)] \u001b[0m\u001b[22m================\u001b[0m\n",
      "\u001b[35m2022-03-26 11:31:23.717 \u001b[0m\u001b[32m[7829/deploy/138414 (pid 4108)] \u001b[0m\u001b[22mEndpoint name is: HBA-RF-endpoint-1648254679131\u001b[0m\n",
      "\u001b[35m2022-03-26 11:31:23.717 \u001b[0m\u001b[32m[7829/deploy/138414 (pid 4108)] \u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2022-03-26 11:31:23.718 \u001b[0m\u001b[32m[7829/deploy/138414 (pid 4108)] \u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2022-03-26 11:33:59.855 \u001b[0m\u001b[32m[7829/deploy/138414 (pid 4108)] \u001b[0m\u001b[22m-----![0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\u001b[0m\n",
      "\u001b[35m2022-03-26 11:34:09.485 \u001b[0m\u001b[32m[7829/deploy/138414 (pid 4108)] \u001b[0m\u001b[22m0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\u001b[0m\n",
      "\u001b[35m2022-03-26 11:34:09.485 \u001b[0m\u001b[32m[7829/deploy/138414 (pid 4108)] \u001b[0m\u001b[22m1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\u001b[0m\n",
      "\u001b[35m2022-03-26 11:34:09.485 \u001b[0m\u001b[32m[7829/deploy/138414 (pid 4108)] \u001b[0m\u001b[22m2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\u001b[0m\n",
      "\u001b[35m2022-03-26 11:34:09.485 \u001b[0m\u001b[32m[7829/deploy/138414 (pid 4108)] \u001b[0m\u001b[22m2 2]\u001b[0m\n",
      "\u001b[35m2022-03-26 11:34:12.488 \u001b[0m\u001b[32m[7829/deploy/138414 (pid 4108)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:34:16.580 \u001b[0m\u001b[32m[7829/end/138415 (pid 4177)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:34:23.806 \u001b[0m\u001b[32m[7829/end/138415 (pid 4177)] \u001b[0m\u001b[22mClassificationFlow is all done.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:34:32.672 \u001b[0m\u001b[32m[7829/end/138415 (pid 4177)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-03-26 11:34:33.887 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python ../flows/RF-deploy.py run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60c79fd6-0ef1-4358-a734-d8988df2b555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]'\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris['data']\n",
    "\n",
    "# Create a low-level client representing Amazon SageMaker Runtime\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region_name='us-west-2')\n",
    "\n",
    "# The name of the endpoint. The name must be unique within an AWS Region in your AWS account. \n",
    "\n",
    "endpoint_name='HBA-RF-endpoint-1648254679131'\n",
    "\n",
    "\n",
    "# csv serialization\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=pd.DataFrame(X).to_csv(header=False, index=False),\n",
    "    ContentType=\"text/csv\",\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4854a66e-e3e0-420f-9aec-4e8985752318",
   "metadata": {},
   "source": [
    "## Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e886b3-654b-4451-8908-954e57fc269e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python RF-deploy-MVP-NB.py resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bb131-1fd9-489e-8486-544838536eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "! export METAFLOW_PROFILE=oleg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb81585-4c90-40ed-bf1d-350888a599cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc0367c-8914-4e71-a230-d0f127eb7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "# Create a low-level client representing Amazon SageMaker Runtime\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region_name='us-west-2')\n",
    "\n",
    "# The name of the endpoint. The name must be unique within an AWS Region in your AWS account. \n",
    "#endpoint_name='RF-endpoint-1648025507362'\n",
    "endpoint_name='RF-endpoint-1648169001436'\n",
    "# endpoint_name='regression-1646368875724-endpoint'\n",
    "endpoint_name='RF-endpoint-1648187750973'\n",
    "\n",
    "\n",
    "# csv serialization\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=pd.DataFrame(X).to_csv(header=False, index=False).encode(\"utf-8\"),\n",
    "    ContentType=\"text/csv\",\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b0337-e49c-4851-b48d-ecb495a40b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d77df92-16d4-4f4c-9093-39addcfe7ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:full-stack-metaflow] *",
   "language": "python",
   "name": "conda-env-full-stack-metaflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
